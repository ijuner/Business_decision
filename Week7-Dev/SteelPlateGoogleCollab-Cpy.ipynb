{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Check GPU availability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if GPU is available\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Display GPU name\n",
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Configure Google Drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Change directory to your dataset\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/Severstal')  # Change this path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Install Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow keras opencv-python matplotlib numpy albumentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load CSV file\n",
    "df = pd.read_csv('/content/drive/MyDrive/Severstal/train.csv')\n",
    "\n",
    "# Drop NaN (if any images do not have segmentation masks)\n",
    "df = df.dropna(subset=['EncodedPixels'])\n",
    "\n",
    "# Unique Image IDs\n",
    "image_ids = df[\"ImageId\"].unique()\n",
    "\n",
    "# Train-Test-Validate Split (70-20-10)\n",
    "train_ids, temp_ids = train_test_split(image_ids, test_size=0.30, random_state=42)\n",
    "val_ids, test_ids = train_test_split(temp_ids, test_size=0.66, random_state=42)  # 20% Test, 10% Validation\n",
    "\n",
    "# Define directories\n",
    "base_dir = \"/content/drive/MyDrive/Severstal/train_images/\"\n",
    "output_dir = \"/content/dataset/\"\n",
    "\n",
    "for folder in [\"train\", \"test\", \"validate\"]:\n",
    "    os.makedirs(os.path.join(output_dir, folder), exist_ok=True)\n",
    "\n",
    "# Function to move files\n",
    "def move_files(image_list, dest_folder):\n",
    "    for img in image_list:\n",
    "        src_path = os.path.join(base_dir, img)\n",
    "        dest_path = os.path.join(output_dir, dest_folder, img)\n",
    "        shutil.copy(src_path, dest_path)\n",
    "\n",
    "# Move images to respective folders\n",
    "move_files(train_ids, \"train\")\n",
    "move_files(test_ids, \"test\")\n",
    "move_files(val_ids, \"validate\")\n",
    "\n",
    "print(f\"✅ Dataset split completed! Train: {len(train_ids)}, Test: {len(test_ids)}, Validate: {len(val_ids)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **U-Net Model Base**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Enable Mixed Precision for Faster Training\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "\n",
    "# U-Net Model with EfficientNet Backbone\n",
    "def build_unet(input_shape=(256, 256, 3)):\n",
    "    inputs = tf.keras.Input(input_shape)\n",
    "\n",
    "    # EfficientNet as Backbone (Feature Extractor)\n",
    "    backbone = EfficientNetB0(include_top=False, input_tensor=inputs, weights=\"imagenet\")\n",
    "    backbone.trainable = False  # Freeze backbone during initial training\n",
    "\n",
    "    # U-Net Decoder\n",
    "    conv1 = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(backbone.output)\n",
    "    up1 = UpSampling2D((2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(up1)\n",
    "    up2 = UpSampling2D((2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(up2)\n",
    "    up3 = UpSampling2D((2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(up3)\n",
    "    up4 = UpSampling2D((2, 2))(conv4)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation=\"sigmoid\")(up4)\n",
    "\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# Compile Model\n",
    "model = build_unet()\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Train the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Image Generators for Data Augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=15, horizontal_flip=True)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load Images in Batches\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"/content/dataset/train/\",\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    \"/content/dataset/validate/\",\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# Save Model\n",
    "model.save(\"/content/drive/MyDrive/Severstal/Collab/steel_defect_unet.h5\")\n",
    "print(\"✅ Model training complete & saved!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Inference**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load Model\n",
    "model = tf.keras.models.load_model(\"/content/drive/MyDrive/Severstal/Collab/steel_defect_unet.h5\")\n",
    "\n",
    "# Load Test Image\n",
    "test_img_path = \"/content/dataset/test/sample.jpg\"\n",
    "test_img = tf.keras.preprocessing.image.load_img(test_img_path, target_size=(256, 256))\n",
    "test_img = np.array(test_img) / 255.0  # Normalize\n",
    "test_img = np.expand_dims(test_img, axis=0)\n",
    "\n",
    "# Predict Mask\n",
    "pred_mask = model.predict(test_img)[0]\n",
    "pred_mask = np.squeeze(pred_mask)  # Remove extra dimensions\n",
    "\n",
    "# Show Results\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(np.squeeze(test_img), cmap=\"gray\")\n",
    "plt.title(\"Original Image\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(pred_mask, cmap=\"jet\", alpha=0.5)\n",
    "plt.title(\"Predicted Mask\")\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
